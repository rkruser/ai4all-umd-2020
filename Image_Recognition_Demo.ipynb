{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Recognition Demo",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19aB7x9YPEauBfvyWAJCbLh8ECpeYKKcc",
      "authorship_tag": "ABX9TyNTc8XuVU7KdavlPSo1b5ye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkruser/ai4all-umd-2020/blob/master/Image_Recognition_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfKldzQk0pk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!git clone https://github.com/rkruser/ai4all-umd-2020.git #https seems to work, but not ssh\n",
        "%cd ai4all-umd-2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFzTR5yc02Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/leafsnap\n",
        "!curl -o ./data/leafsnap/leafsnap.tar http://leafsnap.com/static/dataset/leafsnap-dataset.tar\n",
        "!tar -xvf ./data/leafsnap/leafsnap.tar -C ./data/leafsnap > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SFwezEm1C2N",
        "colab_type": "text"
      },
      "source": [
        "**To get your neural network, follow this drive link** to download \n",
        " [your neural network](https://drive.google.com/file/d/1YH70L-pESc8m4N-vgPjVk6YbnUIEUo6k/view?usp=sharing) trained on leafsnap. (The resnet18 model is not necessary; we are loading a separate resnet50 pretrained on [ImageNet](http://www.image-net.org/)). Save the file on your computer, then manually upload it `ai4all-umd-2020/models/your_model` by using the folder interface on the left side of the Colab. (Expand the desired folder, then click on the three dots to the right of its name, and then click \"upload\").\n",
        "\n",
        "**Uploading may take a minute. The bottom left corner of Colab should show upload progress.** You may get code errors if you try to run cells before the upload is complete.\n",
        "\n",
        "**Note that you will have to re-upload if Colab decides to obliterate your file system.** Manual uploads are the simplest solution for right now. The colab will not be wiped clean too often if you are active on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyuQ7stc1yuE",
        "colab_type": "text"
      },
      "source": [
        "**To run the demo,** run the following code cells in order:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaIb-Apv1DUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run resnet50 pretrained on imagenet, your neural network model,\n",
        "#  and all student image transformations\n",
        "#  Collect results in a dictionary\n",
        "import traceback\n",
        "from flask import Flask, jsonify, request, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "#from utils import read_file, transform_image, get_topk, model  #render_prediction\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "\n",
        "import project_network as pnet\n",
        "import project_train as ptrain\n",
        "import data_loader\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "from data_loader import ClassLoader\n",
        "\n",
        "def read_file(upload=None, url=None):\n",
        "    if (upload is not None) and upload.filename:\n",
        "        in_memory_file = BytesIO()\n",
        "        upload.save(in_memory_file)\n",
        "        img = Image.open(in_memory_file)\n",
        "        return img\n",
        "\n",
        "    elif url is not None:\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        return img\n",
        "\n",
        "    else:\n",
        "        raise NameError('Invalid file/url')\n",
        "\n",
        "def to_base64(img):\n",
        "    buffered = BytesIO()\n",
        "    img.save(buffered, format=\"JPEG\")\n",
        "    return base64.b64encode(buffered.getvalue()).decode('ascii')\n",
        "\n",
        "# Transform input into the form our model expects\n",
        "def transform_image(pil_image):\n",
        "    input_transforms = [\n",
        "        transforms.Resize(255),           # We use multiple TorchVision transforms to ready the image\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.485, 0.456, 0.406],       # Standard normalization for ImageNet model input\n",
        "            [0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ]\n",
        "    my_transforms = transforms.Compose(input_transforms)\n",
        "    timg = my_transforms(pil_image)                       # Transform PIL image to appropriately-shaped PyTorch tensor\n",
        "    timg.unsqueeze_(0)                                    # PyTorch models expect batched input; create a batch of 1\n",
        "    return timg\n",
        "\n",
        "leafsnap_transform_image = transforms.Compose([\n",
        "  transforms.Resize((224,224)),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def get_topk(model, input_tensor, k=5):\n",
        "    outputs = model(input_tensor)                 # Get likelihoods for all ImageNet classes\n",
        "    values, indices = torch.topk(outputs, k)              # Extract top k most likely classes\n",
        "    values = values.data.cpu().numpy()[0]\n",
        "    indices = indices.data.cpu().numpy()[0]\n",
        "    return values, indices\n",
        "\n",
        "resnet50_imagenet_model = models.resnet50(pretrained=True)\n",
        "resnet50_imagenet_model.eval()\n",
        "img_class_map = None\n",
        "mapping_file_path = 'index_to_name.json'                  # Human-readable names for Imagenet classes\n",
        "if os.path.isfile(mapping_file_path):\n",
        "    with open (mapping_file_path) as f:\n",
        "        img_class_map = json.load(f)\n",
        "\n",
        "device = 'cpu' #We don't need to bother with the GPU when testing the trained model on small sets of images\n",
        "your_net = pnet.YourNetwork() # A special argument I added to your network --Ryen\n",
        "net_weights, _ = torch.load('./models/your_model/your_model_49.pth',map_location=device) # The second return value is the optimizer weights, which we don't need now\n",
        "your_net.load_state_dict(net_weights)\n",
        "your_net.eval()\n",
        "leaf_species_name_mapping = ClassLoader()\n",
        "downsize = transforms.Resize(60)\n",
        "\n",
        "# Student image transforms\n",
        "# from Anu import ...\n",
        "# from shubham import ...\n",
        "# from emily import ...\n",
        "# from portia import ...\n",
        "# from kemka import ...\n",
        "# from unity import ...\n",
        "\n",
        "# Need to return a list of dictionaries with keys 'model', 'label', 'score', 'image'\n",
        "# Ryen will write this function and get back to you\n",
        "def collect_outputs(input_pil_image):\n",
        "  resnet50_im = transform_image(input_pil_image)\n",
        "  your_net_im = leafsnap_transform_image(input_pil_image).unsqueeze(0)\n",
        "\n",
        "  r50_vals, r50_inds = get_topk(resnet50_imagenet_model, resnet50_im, 5)\n",
        "  your_vals, your_inds = get_topk(your_net, your_net_im, 5)\n",
        "\n",
        "  image_net_results = []\n",
        "  for value, idx in zip(r50_vals, r50_inds):\n",
        "    image_net_results.append({\n",
        "        \"model\": \"ImageNet Resnet50 Pretrained\",\n",
        "        \"category\": img_class_map.get(str(idx), \"Unknown\")[1],\n",
        "        \"score\": str(value),\n",
        "        \"image\": None\n",
        "    })\n",
        "\n",
        "  your_net_results = []\n",
        "  for value, idx in zip(your_vals, your_inds):\n",
        "    species_name = leaf_species_name_mapping.ind2str(idx)\n",
        "    species_dir = os.path.join('./data/leafsnap/dataset/images/field/',species_name)\n",
        "    species_file = os.listdir(species_dir)[0]\n",
        "    species_file = os.path.join(species_dir, species_file)\n",
        "    your_net_results.append({\n",
        "        \"model\": \"Your Network Trained on Leafsnap\",\n",
        "        \"category\": species_name,\n",
        "        \"score\": str(value),\n",
        "        \"image\": to_base64(downsize(Image.open(species_file)))\n",
        "    })\n",
        "\n",
        "  # In place of \"None\", write\n",
        "  #  to_base64( downsize( student_transform( img ) ) )\n",
        "  #  student_transform must take a PIL image and return a PIL image\n",
        "  #  The returned image must be no larger than 256 by 256, preferably smaller\n",
        "  student_image_transforms = [\n",
        "    {\n",
        "      \"model\": \"Shubham\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None \n",
        "    },\n",
        "    {\n",
        "      \"model\": \"Portia\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None # Fill this in    \n",
        "    },\n",
        "    {\n",
        "      \"model\": \"Kemka\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None # Fill this in    \n",
        "    },\n",
        "    {\n",
        "      \"model\": \"Emily\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None # Fill this in    \n",
        "    },\n",
        "    {\n",
        "      \"model\": \"Unity\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None # Fill this in    \n",
        "    },\n",
        "    {\n",
        "      \"model\": \"Anu\",\n",
        "      \"category\": '-',\n",
        "      \"score\": '-',\n",
        "      \"image\": None # Fill this in    \n",
        "    },\n",
        "  ]\n",
        "\n",
        "  all_results = image_net_results + your_net_results + student_image_transforms\n",
        "\n",
        "  return all_results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0CTF5t91qvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@app.route('/', methods=['GET'])\n",
        "def root():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def predict():\n",
        "    if request.method == 'GET':\n",
        "        try:\n",
        "            url = request.args.get('q')\n",
        "            app.logger.debug('url provided - %s', url)\n",
        "            input_tensor = transform_image(read_file(url=url))\n",
        "            values, indices = get_topk(input_tensor)\n",
        "            results = render_prediction(values, indices)\n",
        "            return jsonify(results=results)\n",
        "\n",
        "        except:\n",
        "            app.logger.debug(\"Error: %s\", traceback.print_exc())\n",
        "            return jsonify(\"invalid image url\")\n",
        "\n",
        "    elif request.method == 'POST':\n",
        "        try:\n",
        "            file = request.files['file']\n",
        "            app.logger.debug('file uploaded - %s', file)\n",
        "            url = request.form.get(\"url\", None)\n",
        "            app.logger.debug('url provided - %s', url)\n",
        "\n",
        "            input_pil_image = read_file(upload=file, url=url)\n",
        "            #values, indices = get_topk(input_tensor)\n",
        "            results = collect_outputs(input_pil_image)\n",
        "            return jsonify(results=results)\n",
        "\n",
        "        except:\n",
        "            app.logger.debug(\"Error: %s\", traceback.print_exc())\n",
        "            return jsonify(\"invalid image\")\n",
        "\n",
        "    else:\n",
        "        app.logger.debug(\"Error: %s\", traceback.print_exc())\n",
        "        return jsonify('invalid request')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBYtrC2Z1uZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_with_ngrok(app)\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}